{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9964552b-62e2-4c5d-8033-44366e428765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahaque2/venv/py3_7/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from NewsSentiment import TargetSentimentClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "779c0ae9-a38e-47b9-a264-cee7b3579903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset and place under dataset/ folder\n",
    "\n",
    "news = pd.read_csv('dataset/news.csv')\n",
    "news_tweets = pd.read_csv('dataset/news_tweets.csv')\n",
    "# user_resp = pd.read_csv('results/user_response.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f0bb873-1d29-41f6-906b-6d50b367132e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35886, 32), (24584, 49))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.shape, news_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a988f65-f7c0-4cd3-be11-bc3e56f0e6da",
   "metadata": {},
   "source": [
    "## Compuate target based sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "897cebf5-3159-445d-8723-affedc0db11d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sentiment_scores(news_tweets, ent):\n",
    "    \n",
    "    news_tweets_filtered = news_tweets[news_tweets.text.str.contains(ent)]\n",
    "    proc_head = []\n",
    "    senti = []\n",
    "    j = 0\n",
    "    tsc = TargetSentimentClassifier()\n",
    "    for i, n in enumerate(news_tweets_filtered.text):\n",
    "        # print(type(n))\n",
    "        k = n.split(ent)\n",
    "        # print(k)\n",
    "        sn = dict()\n",
    "        j+=1\n",
    "        if(ent in n):\n",
    "            # print(x)\n",
    "            # proc_head.append(x)\n",
    "            x = [k[0], ent, k[1]]\n",
    "            sentiment = tsc.infer_from_text(k[0].strip('\\n'), ent, k[1])\n",
    "            # print(x, sentiment)\n",
    "            # print(sentiment[0]['class_label'], sentiment[0]['class_prob'])\n",
    "            sn[sentiment[0]['class_label']] = sentiment[0]['class_prob']\n",
    "            sn[sentiment[1]['class_label']] = sentiment[1]['class_prob']\n",
    "            sn[sentiment[2]['class_label']] = sentiment[2]['class_prob']\n",
    "            senti.append(sn)\n",
    "            print(j, end = \"\\r\")\n",
    "            # sys.exit()\n",
    "        else:\n",
    "            senti.append(None)\n",
    "            \n",
    "    pos_t_senti = [x['positive'] if x != None else None for x in senti]\n",
    "    neg_t_senti = [x['negative'] if x != None else None for x in senti]\n",
    "    neu_t_senti = [x['neutral'] if x != None else None for x in senti]\n",
    "    \n",
    "    news_tweets_filtered['biden_pos_new'] = pos_t_senti\n",
    "    news_tweets_filtered['biden_neg_new'] = neg_t_senti\n",
    "    news_tweets_filtered['biden_neu_new'] = neu_t_senti\n",
    "            \n",
    "    return news_tweets_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2366a615-10b6-4c5a-894c-7d28ccf1921d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahaque2/venv/py3_7/lib/python3.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ahaque2/venv/py3_7/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ahaque2/venv/py3_7/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "news_tweets_filtered_B = get_sentiment_scores(news_tweets, 'Biden')\n",
    "news_tweets_filtered_T = get_sentiment_scores(news_tweets, 'Trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22370800-8340-4e83-9b81-28743454be67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, (35, 49))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_tweets_senti = pd.concat((news_tweets_filtered_B, news_tweets_filtered_T), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f40df05-5af5-44b9-be6e-b5ec4a78861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_tweets_filtered = news_tweets_filtered.drop_duplicates('tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8ada1e61-cd73-4a73-86ce-b3e34982f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_tweets_senti.to_csv('results/news_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd110570-ee29-4f98-b713-c0ef9a7b4fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_7",
   "language": "python",
   "name": "py3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
