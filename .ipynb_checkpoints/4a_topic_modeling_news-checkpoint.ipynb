{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ed511b-44f0-45ad-9f5a-7d43d2445d59",
   "metadata": {},
   "source": [
    "### Topic modeling extended (manual grouping of topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13564d8b-38dc-4b76-a66b-4ff00a708a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "759eb581-1b72-47cf-9c4d-10571d5c3c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('results/news.csv')\n",
    "news_text = news.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "418aa69f-c631-4368-b8f9-85d9f49cee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "exclude_words = ['donald', 'trump', 'joe', 'biden', 'president', 'ad']\n",
    "\n",
    "def preprocess(txt):\n",
    "    \n",
    "    proc_sent = []\n",
    "    for line in txt:\n",
    "        word_tokens = word_tokenize(line)\n",
    "        sent = [w for w in word_tokens if (not w.lower() in stop_words and not w.lower() in exclude_words)]\n",
    "        proc_sent.append(\" \".join(sent))\n",
    "    \n",
    "    return proc_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "da57173c-2380-4a6c-af75-d4f0e3f632a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['processed_text'] = preprocess(news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4241f675-9ac8-4ce7-be44-061dbfa4786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488e263-1ffb-431d-8d52-e4cb092c679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topic_list = [['drug', 'outbreak', 'flu', 'infection', 'contagious', 'treatment', 'prescription', 'covid', 'test', 'virus', 'ventilator', 'deaths', 'cases', 'pandemic', \n",
    "                    'epidemic', 'corona', 'coronavirus', 'covid19', 'patients', 'symptom'],\n",
    "                   ['lockdown', 'shutdown', 'mask', 'distancing', 'masks'],\n",
    "                   ['vaccine', 'vaccination', 'cure', 'moderna', 'pfizer', 'astrazeneca', 'j&j', 'dose'],\n",
    "                   ['education', 'school', 'student', 'teacher', 'children', 'homeschool', 'schools', 'students', 'teachers'],\n",
    "                   ['economy', 'industry', 'business', 'financial', 'finance', 'fiscal', 'economic', 'job', 'jobless', 'investing', 'investor', 'billion', 'gdp', 'debt', \n",
    "                    'liquidity', 'inflation', 'stimulus', 'bill', 'stocks', 'market', 'employment', 'unemployment', 'checks', 'cheques', 'recession', 'bull', 'bullish', 'bear',\n",
    "                    'bearish', 'dow', 's&p', 'nasdaq', 'trade', 'trading', 'tax', 'loan', 'labor', 'buyback', 'selloff', 'wealth', 'wealthy', 'billionare', 'millionare'],\n",
    "                   ['earth', 'green', 'pollution', 'ozone', 'deforestation', 'greenhouse', 'wildfire', 'climate', 'warming', 'temperature', 'flood', 'drought', 'glacier', 'environment', 'environmental', 'carbon', 'emission', 'gas', 'fracking'],\n",
    "                   ['capitol', 'riot', 'siege', 'rioter', 'mob'],\n",
    "                   ['voter', 'absentee', 'ballot', 'fraud', 'mailin', 'stolen', 'voting', 'election', 'black voters'],\n",
    "                   ['immigration', 'immigrant', 'refugee', 'border', 'wall', 'migration', 'h1b', 'visa'],\n",
    "                   ['blm', 'floyd', 'police', 'brutality', 'defund', 'protest', 'protesters', 'officer', 'black lives matter', 'injustice', 'racism', 'racial', 'supremacist'],\n",
    "                   ['abortion', 'wade', 'roe'],\n",
    "                   ['supreme', 'court', 'coney', 'barret', 'packing', 'justice', 'judge'],\n",
    "                   ['security', 'military', 'weapons', 'attack', 'defense', 'gun', 'shooting', 'pentagon'],\n",
    "                   ['international', 'country', 'global', 'china', 'chinese', 'beijing', 'shanghai', 'iran', 'irani', 'iranian', 'tehran', 'afghanistan', 'afghan', 'afghani', 'afghanistani', \n",
    "                    'kabul', 'russia', 'russian', 'moscow', 'britain', 'british', 'brit', 'brexit', 'london', 'Korea', 'Korean', 'kim', 'venezuelan', 'venezuela', 'syrian', 'syria'\n",
    "                    'world', 'worldwide']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e722c65b-cf22-4ee9-914f-03a7589c37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = frozenset(list([\"rt\",\"RT\", \"&\", \"amp\", \"&amp\", \"http\",\"https\", \"http://\", \"https://\", \"fav\", \"FAV\"]))\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words = my_stopwords, min_df=5)\n",
    "\n",
    "# do the BERT topic modelling\n",
    "umap_model = UMAP(n_neighbors=10, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "\n",
    "min_clusters = round(len(headlines) * 0.0017)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size= min_clusters, metric='euclidean', cluster_selection_method='eom', prediction_data=True, min_samples=5)\n",
    "\n",
    "# sentence_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "# embeddings = sentence_model.encode(news_list)\n",
    "\n",
    "#run the model\n",
    "topic_model = BERTopic(seed_topic_list = seed_topic_list, nr_topics = 'auto', umap_model=umap_model, hdbscan_model=hdbscan_model, vectorizer_model=vectorizer_model, low_memory=True, calculate_probabilities=True)\n",
    "\n",
    "topics, probs = topic_model.fit_transform(news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57de0343-a42a-490a-a630-b3c45005bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pickle\n",
    "#Clear cache or restart kernel\n",
    "my_model = BERTopic.load(\"../../bertopic/topic_model\")\n",
    "\n",
    "# topic_model.save(\"bertopic/topic_model_news_tweets\")\n",
    "# pickle.dump(topics, open( \"bertopic/topics_news_tweets.pickle\", \"wb\" ) )\n",
    "# # assert topics == new_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4421ba3a-a8f1-4a13-8621-b72fae97c622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>7930</td>\n",
       "      <td>-1_said_election_coronavirus_people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2785</td>\n",
       "      <td>0_election_ballots_votes_voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2219</td>\n",
       "      <td>1_twitter_facebook_social media_media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1894</td>\n",
       "      <td>2_coronavirus_virus_cases_pandemic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1577</td>\n",
       "      <td>3_capitol_impeachment_inauguration_house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>73</td>\n",
       "      <td>98</td>\n",
       "      <td>73_latino_latinos_florida_voters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>74</td>\n",
       "      <td>96</td>\n",
       "      <td>74_qanon_conspiracy_theory_greene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>75_trade_manufacturing_jobs_workers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>76_says_pm_sessions_2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>77_nuclear_iran_china_us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                      Name\n",
       "0      -1   7930       -1_said_election_coronavirus_people\n",
       "1       0   2785           0_election_ballots_votes_voting\n",
       "2       1   2219     1_twitter_facebook_social media_media\n",
       "3       2   1894        2_coronavirus_virus_cases_pandemic\n",
       "4       3   1577  3_capitol_impeachment_inauguration_house\n",
       "..    ...    ...                                       ...\n",
       "74     73     98          73_latino_latinos_florida_voters\n",
       "75     74     96         74_qanon_conspiracy_theory_greene\n",
       "76     75     78       75_trade_manufacturing_jobs_workers\n",
       "77     76     78                  76_says_pm_sessions_2020\n",
       "78     77     76                  77_nuclear_iran_china_us\n",
       "\n",
       "[79 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8e6c05c7-5c15-4fd7-81ac-6a3962f2b932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahaque2/venv/py3_10/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "\n",
    "# topic_model.save(\"bertopic/topic_model\")\n",
    "# pickle.dump(topics, open( \"bertopic/topics.pickle\", \"wb\" ) )\n",
    "# # assert topics == new_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc72be-60f0-4524-a36d-4042f8e4cc05",
   "metadata": {},
   "source": [
    "#### Merging similar subtopics and grouping based on similarity after manual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "c21139b1-aa29-447b-868c-48270eb93400",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = {'election': {'fraud': [0], 'polls': [22, 25], 'black voters': [33], 'georgia_runoff': [31], 'general': [23]},\n",
    "             'social_media': {'general': [1], 'tiktok': [45]},\n",
    "             'covid': {'general': [2], 'cases': [6], 'precaution': [15], 'vaccine': [21], 'person': [37], 'drugs': [39], 'testing': [51], 'schools': [59, 63], 'equipments': [72]},\n",
    "             'capitol': {'general': [3]},\n",
    "             'floyd': {'general': [4]},\n",
    "             'court': {'general': [5]},\n",
    "             'immigration': {'general': [8]},\n",
    "              'hunter_biden': {'general': [10]},\n",
    "              'pres_debate': {'general': [11]},\n",
    "              'security': {'general': [12, 52]},\n",
    "              'climate': {'general': [14]},\n",
    "              'economy': {'general': [75], 'stimulus': [16], 'tax': [30], 'market': [42]},\n",
    "              'internatinal': {'general': [77], 'china': [7], 'russia': [17], 'britain': [29], 'israel': [47], 'iran': [57]},\n",
    "              'democrats': {'kamala': [9], 'sanders': [26], 'obama': [34], 'cuomo': [46], 'pelosi': [49]}, \n",
    "              'republican': {'convention': [13], 'first_lady': [35], 'pence': [61]},\n",
    "              'abortion': {'general': [41]},\n",
    "              'healthcare': {'general' : [50]},\n",
    "              'proud boys': {'general': [71], 'qanon': [74]},\n",
    "              'other': {'general': [18, 19, 20, 24, 27, 28, 32, 36, 38, 40, 43, 44, 48, 53, 54, 55, 56, 58, 60, 62, 64, 65, 66, 67, 68, 69, 70, 73, 76]},\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "160ec6bf-f470-4cdb-bd60-199d155e2801",
   "metadata": {},
   "outputs": [],
   "source": [
    "### topic Ids\n",
    "topic_cat_dic = dict([(j, i) for i, j in zip([key for key in topic_list], [x for x in range(len(topic_list))])])\n",
    "\n",
    "### topic to cluster id mapping\n",
    "topic_cls_map = dict()\n",
    "for key in topic_list:\n",
    "    cls_ids = []\n",
    "    for k in topic_list[key]:\n",
    "        cls_ids.extend(topic_list[key][k])\n",
    "    topic_cls_map[key] =  cls_ids\n",
    "    \n",
    "cls_to_fine_top = dict()\n",
    "for top in topic_list:\n",
    "    for t in topic_list[top]:\n",
    "        for k in topic_list[top][t]:\n",
    "            cls_to_fine_top[k] = top + \"-\" + t\n",
    "            \n",
    "            \n",
    "tops, fine_top = [], []\n",
    "for t in topics:\n",
    "    \n",
    "    if(t == -1):\n",
    "        tops.append('none')\n",
    "        fine_top.append('none')\n",
    "        continue\n",
    "    for k in topic_cls_map:\n",
    "        if(t in topic_cls_map[k]):\n",
    "            tops.append(k)\n",
    "    fine_top.append(cls_to_fine_top[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "f160ee0c-277e-4aff-b592-3d33fb8bb3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43816, 43816, 43816)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tops), len(topics), len(fine_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "37c832a6-8698-4340-af53-92ac7097a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['topic_ids'] = topics\n",
    "news['topics'] = tops\n",
    "news['subtopic'] = fine_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "f5054c41-8882-4cbd-99a7-6ebacc2bb98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none            7930\n",
       "other           7457\n",
       "covid           5265\n",
       "election        4986\n",
       "social_media    2457\n",
       "internatinal    2392\n",
       "democrats       2039\n",
       "capitol         1577\n",
       "floyd           1386\n",
       "economy         1305\n",
       "court           1277\n",
       "republican      1235\n",
       "security         909\n",
       "immigration      817\n",
       "hunter_biden     737\n",
       "pres_debate      710\n",
       "climate          655\n",
       "abortion         255\n",
       "healthcare       215\n",
       "proud boys       212\n",
       "Name: topics, dtype: int64"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.topics.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "8964a8e8-a82f-434d-8cc0-5dd81b02e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.to_csv('dataset/news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "9713510d-6174-4409-8a2f-318dfc692daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_colwidth = 1000\n",
    "# news[['title', 'publication', 'topics', 'subtopic']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76830f5a-451a-48ee-8d1f-307782e53f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449f654-45f1-454b-a039-9071fc70c046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_10",
   "language": "python",
   "name": "py3_10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
