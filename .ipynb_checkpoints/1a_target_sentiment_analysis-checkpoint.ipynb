{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6921d78e-9cc4-4b45-9c05-b00a3d490b1a",
   "metadata": {},
   "source": [
    "### Code to compute target-based sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de7e52-e96e-406c-9487-dc38e26e301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from NewsSentiment import TargetSentimentClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779c0ae9-a38e-47b9-a264-cee7b3579903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset and place under dataset/ folder\n",
    "\n",
    "news = pd.read_csv('dataset/news.csv')\n",
    "news_tweets = pd.read_csv('dataset/news_tweets.csv')\n",
    "# user_resp = pd.read_csv('results/user_response.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f0bb873-1d29-41f6-906b-6d50b367132e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35886, 32), (24584, 49))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.shape, news_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e02e43-f702-46c0-bef3-148ba5741b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "news = news.sample(10)\n",
    "news_tweets = news_tweets.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a988f65-f7c0-4cd3-be11-bc3e56f0e6da",
   "metadata": {},
   "source": [
    "## Compuate target based sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "897cebf5-3159-445d-8723-affedc0db11d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sentiment_scores(news_tweets, ent):\n",
    "    \n",
    "    news_tweets_filtered = news_tweets[news_tweets.text.str.contains(ent)]\n",
    "    proc_head = []\n",
    "    senti = []\n",
    "    j = 0\n",
    "    tsc = TargetSentimentClassifier()\n",
    "    for i, n in enumerate(news_tweets_filtered.text):\n",
    "        # print(type(n))\n",
    "        k = n.split(ent)\n",
    "        # print(k)\n",
    "        sn = dict()\n",
    "        j+=1\n",
    "        if(ent in n):\n",
    "            # print(x)\n",
    "            # proc_head.append(x)\n",
    "            x = [k[0], ent, k[1]]\n",
    "            sentiment = tsc.infer_from_text(k[0].strip('\\n'), ent, k[1])\n",
    "            # print(x, sentiment)\n",
    "            # print(sentiment[0]['class_label'], sentiment[0]['class_prob'])\n",
    "            sn[sentiment[0]['class_label']] = sentiment[0]['class_prob']\n",
    "            sn[sentiment[1]['class_label']] = sentiment[1]['class_prob']\n",
    "            sn[sentiment[2]['class_label']] = sentiment[2]['class_prob']\n",
    "            senti.append(sn)\n",
    "            print(j, end = \"\\r\")\n",
    "            # sys.exit()\n",
    "        else:\n",
    "            senti.append(None)\n",
    "            \n",
    "    pos_t_senti = [x['positive'] if x != None else None for x in senti]\n",
    "    neg_t_senti = [x['negative'] if x != None else None for x in senti]\n",
    "    neu_t_senti = [x['neutral'] if x != None else None for x in senti]\n",
    "    \n",
    "    news_tweets_filtered['biden_pos_new'] = pos_t_senti\n",
    "    news_tweets_filtered['biden_neg_new'] = neg_t_senti\n",
    "    news_tweets_filtered['biden_neu_new'] = neu_t_senti\n",
    "            \n",
    "    return news_tweets_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2366a615-10b6-4c5a-894c-7d28ccf1921d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    }
   ],
   "source": [
    "news_tweets_filtered_B = get_sentiment_scores(news_tweets, 'Biden')\n",
    "news_tweets_filtered_T = get_sentiment_scores(news_tweets, 'Trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22370800-8340-4e83-9b81-28743454be67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "news_tweets_senti = pd.concat((news_tweets_filtered_B, news_tweets_filtered_T), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f40df05-5af5-44b9-be6e-b5ec4a78861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_tweets_filtered = news_tweets_filtered.drop_duplicates('tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8ada1e61-cd73-4a73-86ce-b3e34982f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_tweets_senti.to_csv('results/news_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd110570-ee29-4f98-b713-c0ef9a7b4fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_7",
   "language": "python",
   "name": "py3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
